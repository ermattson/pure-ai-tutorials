{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 18px;\">\n",
    "  This is the accompanying code for the post titled \"Understanding GAN Training Strategies, Ethical Implications, and Building Your First GAN with PyTorch\"<br>\n",
    "  You can find it <a href=\"https://pureai.substack.com/p/implement-a-gan-with-pytorch\">here</a>.<br>\n",
    "  Published: January 13, 2024<br>\n",
    "  <a href=\"https://pureai.substack.com\">https://pureai.substack.com</a>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to this Jupyter notebook! If you're new to Python or don't have it installed on your system, don't worry; you can still follow along and explore the code.\n",
    "\n",
    "Here's a quick guide to getting started:\n",
    "\n",
    "- Using an Online Platform: You can run this notebook in a web browser using platforms like Google Colab or Binder. These services offer free access to Jupyter notebooks and don't require any installation.\n",
    "- Installing Python Locally: If you'd prefer to run this notebook on your own machine, you'll need to install Python. A popular distribution for scientific computing is Anaconda, which includes Python, Jupyter, and other useful tools.\n",
    "  - Download Anaconda from [here](https://www.anaconda.com/download).\n",
    "  - Follow the installation instructions for your operating system.\n",
    "  - Launch Jupyter Notebook from Anaconda Navigator or by typing jupyter notebook in your command line or terminal.\n",
    "- Opening the Notebook: Once you have Jupyter running, navigate to the location of this notebook file (.ipynb) and click on it to open.\n",
    "- Running the Code: You can run each cell in the notebook by selecting it and pressing Shift + Enter. Feel free to modify the code and experiment with it.\n",
    "- Need More Help?: If you're new to Python or Jupyter notebooks, you might find these resources helpful:\n",
    "  - [Python.org's Beginner's Guide](https://docs.python.org/3/tutorial/index.html)\n",
    "  - [Jupyter Notebook Basics](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Notebook%20Basics.html)\n",
    "\n",
    "_Note: this Notebook/Code feature the use of Poetry, a dependency and virtual environment manager. If you don't have Poetry, please install it via the Python package manager pip. Then change directories to this code, and run `poetry install --no-root`, which will install all of th required dependencies for you. You then select the poetry virtual environment as your Python kernel._\n",
    "\n",
    "Happy coding, and enjoy exploring the fascinating world of GANs with PyTorch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(f'PyTorch version= {torch.__version__}')\n",
    "print(f'torchvision version= {torchvision.__version__}')\n",
    "print(f'CUDA available= {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # CUDA Installation\n",
    "    print('CUDA Version')\n",
    "    !nvcc --version\n",
    "    print()\n",
    "\n",
    "    # CUDNN Installation\n",
    "    print(f'CUDNN Version: {torch.backends.cudnn.version()}')\n",
    "    print(f'Number of CUDA Devices: {torch.cuda.device_count()}')\n",
    "    print(f'Active CUDA Device: {torch.cuda.current_device()}')\n",
    "    print(f'Available devices: {torch.cuda.device_count()}, Name: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Current CUDA device: {torch.cuda.current_device()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as vtransforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True  # Might benefit if the nnet instance remains same\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hide some PyTorch warnings (bugs)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training and testing datasets from a path with resize and normalization\n",
    "def get_dataloader(_img_size, _bs, _ds, _path):\n",
    "    train_ds = _ds(\n",
    "        root=_path, download=True, train=True,\n",
    "        transform=vtransforms.Compose([\n",
    "            vtransforms.Resize(_img_size),\n",
    "            vtransforms.ToTensor(),\n",
    "            vtransforms.Normalize((0.5,), (0.5,))\n",
    "        ]))\n",
    "\n",
    "    # Use pin_memory=True to fix GPU memory\n",
    "    train_dl = torch.utils.data.DataLoader(train_ds, batch_size=_bs, shuffle=True,\n",
    "                                           # pin_memory=True,\n",
    "                                           num_workers=4)\n",
    "\n",
    "    test_ds = _ds(\n",
    "        root=_path, download=True, train=False,\n",
    "        transform=vtransforms.Compose([\n",
    "            vtransforms.Resize(_img_size),\n",
    "            vtransforms.ToTensor(),\n",
    "            vtransforms.Normalize((0.5,), (0.5,))\n",
    "        ]))\n",
    "\n",
    "    test_dl = torch.utils.data.DataLoader(test_ds, batch_size=_bs, shuffle=True,\n",
    "                                          # pin_memory=True,\n",
    "                                          num_workers=4)\n",
    "\n",
    "    return train_dl, test_dl\n",
    "\n",
    "def get_dl_mnist(_img_size, _bs):\n",
    "    return get_dataloader(_img_size, _bs, dset.MNIST, './MNIST')\n",
    "\n",
    "def get_dl_fashionmnist(_img_size, _bs):\n",
    "    return get_dataloader(_img_size, _bs, dset.FashionMNIST, './fashion-mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize conv layers with N(0,0.02), batch norm layers N(1,0.02) and 0 bias\n",
    "def init_weights(_m):\n",
    "    if isinstance(_m, nn.Conv2d) or isinstance(_m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(_m.weight, mean=0.0, std=0.02)\n",
    "    if isinstance(_m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(_m.weight, mean=1.0, std=0.02)\n",
    "        _m.bias.data.fill_(0.0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_CHANNEL = 1\n",
    "D_HIDDEN= 64\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(IMG_CHANNEL, D_HIDDEN, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(D_HIDDEN, D_HIDDEN*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(D_HIDDEN*2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(D_HIDDEN*2, D_HIDDEN*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(D_HIDDEN*4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(D_HIDDEN*4, D_HIDDEN*8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(D_HIDDEN*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(D_HIDDEN*8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, _input):\n",
    "        return self.net(_input).view(-1, 1).squeeze(1)\n",
    "\n",
    "# Check the network layers\n",
    "print(Discriminator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_DIM= 100\n",
    "G_HIDDEN= 64\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "\n",
    "            nn.ConvTranspose2d(Z_DIM, G_HIDDEN*8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN*8),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(G_HIDDEN*8, G_HIDDEN*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN*4),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(G_HIDDEN*4, G_HIDDEN*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(G_HIDDEN*2, G_HIDDEN, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(G_HIDDEN, IMG_CHANNEL, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, _input):\n",
    "        return self.net(_input)\n",
    "\n",
    "# Check the network layers\n",
    "print(Generator())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper function to make an output directory, as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def mkdir(dir):\n",
    "    try:\n",
    "        if not os.path.exists(dir):\n",
    "            os.mkdir(dir)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "mkdir('gan_output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X_DIM= 64\n",
    "BATCH_SIZE= 1000\n",
    "ETA= 1e-3\n",
    "\n",
    "train_dl, test_dl = get_dl_fashionmnist(X_DIM, BATCH_SIZE)\n",
    "\n",
    "# Create the Discriminator and place it in gpu\n",
    "netD = Discriminator().to(device)\n",
    "netD.apply(init_weights)\n",
    "\n",
    "# Create the Generator and place it in gpu\n",
    "netG = Generator().to(device)\n",
    "netG.apply(init_weights)\n",
    "\n",
    "# Optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=ETA, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=ETA, betas=(0.5, 0.999))\n",
    "\n",
    "info= True\n",
    "EPOCHS= 30\n",
    "\n",
    "# Learning the real and fake - reminder this is not a classification problem\n",
    "REAL_LABEL= 1\n",
    "FAKE_LABEL= 0\n",
    "\n",
    "gan_d_avg_loss = []\n",
    "gan_g_avg_loss = []\n",
    "\n",
    "# Same noise sample to generate the sample fake\n",
    "viz_noise = torch.randn(BATCH_SIZE, Z_DIM, 1, 1, device=device)\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    d_loss_accum = 0\n",
    "    g_loss_accum = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    for i, data in enumerate(train_dl):\n",
    "        x_real = data[0].to(device)\n",
    "        real_label = torch.full((x_real.size(0),), REAL_LABEL, dtype=torch.float32, device=device)\n",
    "        fake_label = torch.full((x_real.size(0),), FAKE_LABEL, dtype=torch.float32, device=device)\n",
    "\n",
    "        # Update D with real data\n",
    "        netD.zero_grad()\n",
    "        y_real = netD(x_real)\n",
    "        loss_D_real = criterion(y_real, real_label)\n",
    "        loss_D_real.backward()\n",
    "\n",
    "        # Update D with fake data\n",
    "        z_noise = torch.randn(x_real.size(0), Z_DIM, 1, 1, device=device)\n",
    "        x_fake = netG(z_noise)\n",
    "        y_fake = netD(x_fake.detach())\n",
    "        loss_D_fake = criterion(y_fake, fake_label)\n",
    "        loss_D_fake.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        loss_D = loss_D_real + loss_D_fake\n",
    "        d_loss_accum += loss_D.item()\n",
    "\n",
    "        # Update G with fake data\n",
    "        netG.zero_grad()\n",
    "        y_fake_r = netD(x_fake)\n",
    "        loss_G = criterion(y_fake_r, real_label)\n",
    "        g_loss_accum += loss_G.item()\n",
    "        batch_count += 1\n",
    "        loss_G.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if info:\n",
    "            sys.stderr.write(\"\\r{:03d}/{:3d} | LossDr: {:6.2f} | lossDf: {:6.2f} | lossG: {:6.2f}\".format(\n",
    "                e+1, EPOCHS, loss_D_real.mean().item(), loss_D_fake.mean().item(), loss_G.mean().item()))\n",
    "            sys.stderr.flush()\n",
    "\n",
    "            if i == 0:\n",
    "                with torch.no_grad():\n",
    "                    viz_sample = netG(viz_noise)\n",
    "                    vutils.save_image(vutils.make_grid(viz_sample[:32], nrow=4),\n",
    "                                      f'./gan_output/fake_samples_{e}.png', normalize=True)\n",
    "\n",
    "    if info:\n",
    "        torch.save(netG.state_dict(), f'./gan_output/netG_{e}.pth')\n",
    "        torch.save(netD.state_dict(), f'./gan_output/netD_{e}.pth')\n",
    "\n",
    "    gan_d_avg_loss.append(d_loss_accum / batch_count)\n",
    "    gan_g_avg_loss.append(g_loss_accum / batch_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the saved weights and generate some fake images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG2 = Generator()\n",
    "netG2.load_state_dict(torch.load(f'./gan_output/netG_{EPOCHS-1:d}.pth'))\n",
    "netG2.to(device)\n",
    "\n",
    "plt.figure(1, figsize=(10, 5), dpi=72)\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    with torch.no_grad():\n",
    "        x_fake = netG2(torch.randn(1, Z_DIM, 1, 1, device=device))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x_fake.to('cpu').numpy().reshape(64,64), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing the training of the GAN, we can illustrate the evolution of the network's learning process, showcasing how it progressively refined its weights to accurately generate computer-simulated images of clothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_strip(_row, _col, _offset, _path):\n",
    "    # epoch\n",
    "    ix = (0, 1, 2, 5, 10, 15, 20, 25, 29, EPOCHS-1)\n",
    "    # position excluding the grid\n",
    "    def img_xy(x, y):\n",
    "        return 2*(x+1)+64*x, 2*(y+1)+64*y\n",
    "\n",
    "    x, y = img_xy(_row,_col)\n",
    "    for i, e in enumerate(ix):\n",
    "        img = plt.imread(f'./{_path}/fake_samples_{e}.png')\n",
    "        plt.subplot(4, 10, 10*_offset + i+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img[x:x+64,y:y+64], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "\n",
    "plt.figure(1, figsize=(20, 10), dpi=72)\n",
    "draw_strip(0,0,0, 'gan_output')\n",
    "draw_strip(1,0,1, 'gan_output')\n",
    "draw_strip(2,2,2, 'gan_output')\n",
    "draw_strip(3,0,3, 'gan_output')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
