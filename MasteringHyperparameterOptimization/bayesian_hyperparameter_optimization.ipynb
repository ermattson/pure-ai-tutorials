{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 18px;\">\n",
    "  This is the accompanying code for the post titled \"Mastering Hyperparameter Optimization: Unlocking the Full Potential of Supervised Learning Models with Code\"<br>\n",
    "  You can find it <a href=\"https://pureai.substack.com/p/mastering-hyperparameter-optimization\">here</a>.<br>\n",
    "  Published: October 20, 2023<br>\n",
    "  <a href=\"https://pureai.substack.com\">https://pureai.substack.com</a>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to this Jupyter notebook! If you're new to Python or don't have it installed on your system, don't worry; you can still follow along and explore the code.\n",
    "\n",
    "Here's a quick guide to getting started:\n",
    "\n",
    "- Using an Online Platform: You can run this notebook in a web browser using platforms like Google Colab or Binder. These services offer free access to Jupyter notebooks and don't require any installation.\n",
    "- Installing Python Locally: If you'd prefer to run this notebook on your own machine, you'll need to install Python. A popular distribution for scientific computing is Anaconda, which includes Python, Jupyter, and other useful tools.\n",
    "  - Download Anaconda from [here](https://www.anaconda.com/download).\n",
    "  - Follow the installation instructions for your operating system.\n",
    "  - Launch Jupyter Notebook from Anaconda Navigator or by typing jupyter notebook in your command line or terminal.\n",
    "- Opening the Notebook: Once you have Jupyter running, navigate to the location of this notebook file (.ipynb) and click on it to open.\n",
    "- Running the Code: You can run each cell in the notebook by selecting it and pressing Shift + Enter. Feel free to modify the code and experiment with it.\n",
    "- Need More Help?: If you're new to Python or Jupyter notebooks, you might find these resources helpful:\n",
    "  - [Python.org's Beginner's Guide](https://docs.python.org/3/tutorial/index.html)\n",
    "  - [Jupyter Notebook Basics](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Notebook%20Basics.html)\n",
    "\n",
    "Happy coding, and enjoy exploring the fascinating world of Hyperparameter Tuning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Hyperparameter Optimization\n",
    "\n",
    "As we covered in the post, Bayesian Optimization is a probabilistic model-based optimization technique aimed at finding the minimum of any function that returns a real-value metric. It is particularly well-suited for optimizing complex, high-dimensional functions that are expensive to evaluate. In machine learning, it can be used for hyperparameter tuning, effectively replacing grid search and random search methods. Today, we'll see how to apply Bayesian Optimization to optimize the hyperparameters of a RandomForestClassifier using the bayes_opt library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Setup\n",
    "\n",
    "First, let's complete the code setup. We have the run_classifier function, which takes in a classifier and returns the mean and standard deviation of accuracy, as well as the mean True Positive Rate (TPR) and False Positive Rate (FPR). This function uses 10-fold stratified cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "optimized_log_data = []\n",
    "\n",
    "def run_classifier(classifier, log_progress=False):\n",
    "    global feature_data, target_data, optimized_log_data\n",
    "    X_data, y_data = feature_data, target_data\n",
    "    true_positive_rates = []\n",
    "    false_positive_rates = []\n",
    "    accuracies = []\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    \n",
    "    for train_indices, test_indices in kfold.split(X_data, y_data):\n",
    "        classifier.fit(X_data[train_indices], y_data[train_indices])\n",
    "        y_predicted = classifier.predict(X_data[test_indices])\n",
    "        \n",
    "        acc = accuracy_score(y_data[test_indices], y_predicted)\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(y_data[test_indices], y_predicted, labels=[1, 0]).ravel()\n",
    "        \n",
    "        true_positive_rate = tp / (tp + fn)\n",
    "        false_positive_rate = fp / (fp + tn)\n",
    "        \n",
    "        true_positive_rates.append(true_positive_rate)\n",
    "        false_positive_rates.append(false_positive_rate)\n",
    "        \n",
    "    mean_tpr = np.mean(true_positive_rates)\n",
    "    mean_fpr = np.mean(false_positive_rates)\n",
    "    \n",
    "    if log_progress:\n",
    "        optimized_log_data.append((mean_tpr, mean_fpr))\n",
    "        \n",
    "    return np.mean(accuracies), np.std(accuracies), mean_tpr, mean_fpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The costf function is our objective function that we aim to maximize. It takes in hyperparameters for the Random Forest Classifier and returns the cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "def avg(_x):\n",
    "    return (_x[0]+_x[1])/2.\n",
    "\n",
    "def costf(_X):  # BOP maximizes\n",
    "    def costf(_pd, _pf):\n",
    "        return 5*(1.-_pd)+_pf\n",
    "\n",
    "    S = _X.shape[0]  # number of particles\n",
    "    costs = np.ones((S,), dtype=float)\n",
    "\n",
    "    for i in range(S):\n",
    "        hp = np.array(_X[i], int)  # hyperparameters are integers\n",
    "        clf = RandomForestClassifier(n_estimators=hp[0], max_depth=hp[1], max_features=hp[2], n_jobs=-1)\n",
    "        acc, std, tpr, fpr = run_classifier(clf, True)\n",
    "        costs[i] = costf(tpr, fpr)\n",
    "\n",
    "    return costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating some random test data (X_train, y_train) that we'll use for our example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Create random data\n",
    "feature_data, target_data = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Hyperparameter Bounds\n",
    "\n",
    "Before we run the Bayesian Optimization, let's set the bounds for the hyperparameters we are interested in tuning. For the Random Forest Classifier, we'll be tuning:\n",
    "- Number of estimators (num_estimators)\n",
    "- Maximum depth (max_depth)\n",
    "- Maximum features (max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bounds for the hyperparameters\n",
    "NUM_ESTIMATORS = (10, 100)\n",
    "MAX_DEPTH = (1, 10)\n",
    "MAX_FEATURES = (1, 5)\n",
    "\n",
    "pbounds = {'num_estim': NUM_ESTIMATORS, 'max_depth': MAX_DEPTH, 'max_features': MAX_FEATURES}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Objective Function for Bayesian Optimization\n",
    "\n",
    "The function costf_bop is what the Bayesian Optimization will maximize. It's a wrapper around costf, converting the hyperparameters and preparing them for costf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(num_estimators, max_depth, max_features):  # Bayesian Op maximizes\n",
    "    cost = costf(np.array([num_estimators, max_depth, max_features]).reshape(-1, 3))\n",
    "    return -cost[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Bayesian Optimization\n",
    "\n",
    "Now, let's set up and run the Bayesian Optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Initialize Bayesian Optimization\n",
    "boptim = BayesianOptimization(\n",
    "    f=optimizer,\n",
    "    pbounds=pbounds,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "NUM_ITERATIONS = 20\n",
    "optimized_log_data = []  # Holds the Pd Pf\n",
    "\n",
    "# Run the optimizer\n",
    "boptim.maximize(init_points=3, n_iter=NUM_ITERATIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Best Parameters\n",
    "\n",
    "After the optimization is complete, let's look at the best parameters and costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"cost= {boptim.max['target']:.3f}\")\n",
    "bop_op_params = [int(boptim.max['params']['num_estimators']), int(boptim.max['params']['max_depth']), int(boptim.max['params']['max_features'])]\n",
    "print(f\"OP params= {bop_op_params}\")\n",
    "\n",
    "# best OP\n",
    "_, _, bop_tpr, bop_fpr = run_classifier(\n",
    "    RandomForestClassifier(n_estimators=bop_op_params[0],\n",
    "                           max_depth=bop_op_params[1], max_features=bop_op_params[2], n_jobs=-1))\n",
    "\n",
    "Fpr1, Tpr1 = [_[1] for _ in optimized_log_data], [_[0] for _ in optimized_log_data]\n",
    "Std1 = 0.02*np.ones((len(Tpr1),), dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve\n",
    "\n",
    "Finally, let's plot the Receiver Operating Characteristic (ROC) curve to visualize the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotr(_ax, _fpr, _tpr, _std0, _label, op=None):\n",
    "    _ax.scatter(_fpr, _tpr, s=_std0 * 1000, marker='o', c='r', edgecolors='k', alpha=0.8, label=_label)\n",
    "    if op is not None:\n",
    "        _ax.scatter(op[0], op[1], s=50, marker='d', c='b', label='OP')\n",
    "    _ax.plot(np.arange(0.001,1,0.01), np.arange(0.001,1,0.01), linestyle='--', color=(0.6, 0.6, 0.6), label='coin flip')\n",
    "    _ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "    _ax.grid()\n",
    "    _ax.legend()\n",
    "\n",
    "_, ax = plt.subplots(1, 1, figsize=(10, 6), dpi=72)\n",
    "\n",
    "Fpr1, Tpr1 = [_[1] for _ in optimized_log_data], [_[0] for _ in optimized_log_data]\n",
    "Std1 = 0.02*np.ones((len(Tpr1),), dtype=float)\n",
    "\n",
    "plotr(ax, Fpr1, Tpr1, Std1, 'Bayesian Optimization', op=(bop_fpr, bop_tpr))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there you have it! This is a simple but effective demonstration of how Bayesian Optimization can be applied for hyperparameter tuning in machine learning models. Happy tuning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
